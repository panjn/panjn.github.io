{"pages":[{"title":"404 Not Found","text":"","link":"/404.html"}],"posts":[{"title":"(云计算) 如何解决Serverless函数冷启动的问题？","text":"背景 如果你的PaaS能够有效地在20毫秒内启动实例并运行半秒,那么就可以称之为Serverless。 —— AWS云架构战略副总裁Adrian Cockcroft1 Serverless的最大卖点之一就是在做弹性伸缩时可以将实例数缩到0，没流量时不花钱，有流量来时再扩容。然而理想很丰满，现实很骨感。 无论是在流量刚到达时实例数从0到1，还是为了处理更多的流量将实例数从m扩到n的过程，不得不面对的一个问题就是：冷启动。冷启动时间太长， 就会出现请求超时。 何为冷启动 冷启动是指在函数调用链路中包含了资源调度、镜像/代码下载、启动容器、运行时初始化、用户代码初始化等环节。当冷启动完成后，函数实例就绪， 后续请求就能直接被函数执行2。 传统的优化方案尽量避免冷启动 某个实例处理完请求后，不会因为后面2，3分钟没流量就被销毁。各个厂商都会让其继续存在一段时间，比如30分钟。 预热 Amazon EventBridge。搞个定时任务定时去触发Lambda实例，比如每5分钟触发一次3。 “这样在真正想要处理的事件抵达之前，就会有已经被预热 Lambda 保持激活状态以等待响应”。这种方法也可以用来处理在出现时间上具有规律的流量高峰。 预置并发。”预置并发是 AWS Lambda 在 2019 年推出的一个功能，该功能能够指定处于激活状态的 Lambda 实例数量，使函数保持初始化状态”。 在k8s就是相当于给HPA设定个最小副本数呗3。 除了浪费资源，上面的策略也无法解决突发流量场景下从m扩到n时的冷启动问题。 调度 （腾讯）降低调度复杂度4。 原有的调度模块需要考虑的维度很多： 数十种虚拟机的配置、CPU/内存/存储/网络等亲和性和反亲和性、 部署组的需求-跨宿主机，交换机，机架、资源利用率、碎片填充...... 轻量化调度模块：少数的虚拟机配置、宿主机的可用资源离线计算 容器启动 （腾讯）轻量级虚拟机4。 网络 （腾讯）SCF网络4 镜像/代码下载 （平台侧）代码缓存4。 （用户侧）既然代码下载耗时，那你尽可能减小代码包的大小吧。比如在程序中移除不必要的代码、减少不必要的第三方库依赖等。 运行时初始化 如果是用Java, 可以禁掉JVM的分层编译以降低运行速度的代价来换取启动速度的提升3。 其它优化方案WebAssembly WebAssembly 与 Kubernetes 双剑合璧：机遇与挑战 云原生的 WebAssembly 能取代 Docker 吗？ IsolatesCloudFlare的方案 Cloud Computing without Containers 其Serverless平台Workers已宣称零冷启动时间。 Say goodbye to cold starts—support for 0ms worldwide 各个厂商的冷启动时延? 参考链接 AWS 从IaaS到FaaS—— Serverless架构的前世今生 美团 Serverless平台Nest的探索与实践 亚马逊 降低AWS Lambda 冷启动时间的4种方案 腾讯云 Go FaaSter ：Serverless平台冷启动优化 持续更新中...","link":"/pages/serverless-coldstart/"},{"title":"大数据技术综述","text":"本文为对2014年的大数据技术综述论文《Big Data: A Survey》的翻译，论文作者为 Min Chen、Shiwen Mao和Yunhao Liu 英文版论文地址 Big Data: A Survey. 摘要在本文中，我们回顾了大数据的背景和最新技术。 我们首先介绍了大数据的一般背景，并回顾了相关技术， 如云计算、物联网、数据中心和Hadoop。 然后我们聚焦于大数据价值链的四个阶段，即数据生成、数据获取、数据存储和数据分析。 对于每个阶段，我们都会介绍一般背景、讨论技术挑战并回顾最新进展。 最后，我们研究了大数据的几个代表性应用， 包括企业管理、物联网、在线社交网络、医疗应用、集体智能和智能电网。 这些讨论旨在为读者提供这个令人兴奋的领域的一个全面的和宏观的概述。 本次综述以对开放问题和未来方向的讨论结束。 背景大数据时代的黎明在过去的20年里，各个领域的数据都有了大规模的增长。根据国际数据公司（International Data Corporation, IDC）的报告， 2011年全球创建和复制的数据总量为1.8ZB（约为$10^{21}$字节），在五年内增长了近9倍1。 未来，这个数字至少每两年就会翻一番。 在全球数据的爆炸式增长的背景下，大数据一词主要用于描述庞大的数据集。与传统数据集相比，大数据通常包含大量需要实时处理的非结构化数据。 大数据给予了我们发现数据背后隐藏价值的机遇，也带来了新的挑战，比如，如何高效的组织和管理大规模的数据。 最近，行业对大数据的巨大潜力产生了兴趣，许多政府机构宣布了加快大数据研究和应用的重大计划2。 此外，大数据问题经常被 公共媒体报道，如经济学人3,4、纽约时报5国家公共广播电台6,7。两大顶级科学期刊 Nature和Science也开设了专栏，讨论大数据的挑战和影响8,9。毋庸置疑，大数据时代已经来临。 如今，与互联网公司服务相关的大数据增长迅速。例如，谷歌处理数百个PB的数据， Facebook每月产生超过10pb的日志数据，百度处理数十个PB的数据， 阿里巴巴旗下的淘宝每天产生数十个TB的在线交易数据。图1展示了全球数据量的增长。 大型数据集的数量急剧增加的同时，也带来了许多具有亟待解决的富有挑战性的问题: 信息技术 (IT) 的最新进展使生成数据变得更加容易。 例如，平均每分钟有 72 小时的视频上传到 YouTube11。 因此，我们面临的主要挑战之一是从广泛分布的数据源收集和整合海量数据。 云计算和物联网的快速发展进一步推动了数据的急剧增长。云计算为数据资产提供了保障、访问场所和渠道。 在物联网的范式中，世界各地的传感器都在收集和传输数据，并在云中存储和处理。这样的数据无论在数量上还是相互关系上都将远远超过现有企业的IT架构和基础设施的能力， 日益增长的数据带来的另一个问题是，在硬件和软件基础设施有限的情况下，如何存储和管理如此庞大的异构数据集。 考虑到大数据的异构性、可扩展性、实时性、复杂性和私密性等特点，在分析、建模、可视化和预测等过程中， 需要对不同层次的数据集进行有效的“挖掘”，以揭示其内在属性，提高决策能力。 大数据的定义和特点大数据是一个抽象的概念。 除了意味着海量数据之外，它还有一些其他的特性，决定了它与“海量数据”或“超大数据”的区别。 目前，虽然大数据的重要性已得到普遍认可，但人们对其定义仍有不同看法。 一般来说，大数据是指传统的IT和软/硬件工具无法在可容忍的时间内感知、获取、管理和处理的数据集。 由于关注点不同，科技企业、研究学者、数据分析师、技术从业者对大数据的定义不同。 以下定义可以帮助我们更好地理解大数据的深刻社会、经济和技术内涵。 在2010年，Apache Hadoop将大数据定义为“在可接受的范围内，一般计算机无法捕获、管理和处理的数据集”。基于这一定义，2011年5月，全球咨询机构麦肯锡公司(McKinsey &amp; Company)宣布，大数据将成为创新、竞争和生产力的下一个前沿领域。大数据是指传统数据库软件无法获取、存储和管理的数据集。这一定义包括两个内涵:第一，符合大数据标准的数据集的容量在变化，可能会随着时间或技术的进步而增长;其次，在不同的应用中，符合大数据标准的数据量是不同的。目前，大数据一般在几TB到几PB10之间。从麦肯锡公司的定义可以看出，数据集的大小并不是衡量大数据的唯一标准。日益增长的数据规模和传统数据库技术无法处理的数据管理是接下来的两个关键特征。 事实上，早在2001年，人们就对大数据进行了定义。META(现为Gartner)的分析师Doug Laney在一份研究报告12中，用3Vs模型定义了数据增加带来的挑战和机遇，即Volume、Velocity和Variety的增加。虽然这个模型最初并没有被用来定义大数据，但是Gartner等许多企业，包括IBM13和微软14的一些研究部门，在接下来的十年15中仍然使用“3v”模型来描述大数据。在“3v”模型中，Volume意味着随着海量数据的产生和收集，数据规模越来越大;速度是指大数据的及时性，数据采集、分析等工作必须快速、及时地进行，才能最大限度地利用大数据的商业价值;多样性是指各种类型的数据，包括半结构化和非结构化数据，如音频、视频、网页、文本等，也包括传统的结构化数据。 然而，也有人持不同意见，其中包括IDC，大数据及其研究领域最具影响力的领导者之一。2011年，IDC的一份报告将大数据定义为:“大数据技术描述了新一代的技术和架构，旨在通过高速捕获、发现和/或分析，从各种各样的大量数据中经济地提取价值。”IBM1这个定义,大数据的特点可以概括为四个Vs。、Volume(大容量),Variety(各种形式)、Velocity(快速生成)和Value(价值巨大但密度低),如图2所示。这样的4v定义被广泛认可，因为它强调了大数据的意义和必要性，即挖掘隐藏的巨大价值。这一定义指出了大数据中最关键的问题，即如何从规模巨大、类型多样、生成迅速的数据集中发现价值。正如Facebook的副总工程师Jay Parikh所说:“如果你不利用收集到的数据，你只能拥有一堆数据，而不是大数据11。” 此外，NIST将大数据定义为“大数据是指数据量、采集速度或数据表示限制了使用传统关系方法进行有效分析的能力的数据，或可以通过重要的水平缩放技术有效处理的数据”。它专注于大数据的技术方面。这表明需要开发有效的方法或技术来分析和处理大数据。 业界和学术界对大数据的定义都有相当多的讨论16,17。大数据研究除了要有一个正确的定义外，还应该关注如何提取其价值，如何使用数据，如何将“一堆数据”转化为“大数据”。 大数据的价值麦肯锡公司在深入研究美国医疗保健、欧盟公共部门管理、美国零售、全球制造业和全球个人位置数据后，观察了大数据如何创造价值。麦肯锡报告通过对代表全球经济的五个核心产业的研究指出，大数据可以充分发挥经济功能，提高企业和公共部门的生产力和竞争力，为消费者创造巨大利益。在[10]中，麦肯锡总结了大数据可以创造的价值：如果能够创造性地、有效地利用大数据来提高效率和质量，美国医疗行业通过数据获得的潜在价值可能超过 3000 亿美元，从而减少美国医疗保健支出超过 8%；充分利用大数据的零售商可以将利润提高60%以上；大数据还可用于提高政府运营效率，欧洲发达经济体可节省超过 1000 亿欧元（不包括减少欺诈、错误和税收差异的影响）。 麦肯锡的报告被认为具有前瞻性和预测性，而以下事实可能验证大数据的价值。 2009年流感大流行期间，谷歌通过分析大数据及时获取信息，提供的信息甚至比疾病预防中心提供的信息更有价值。几乎所有国家都要求医院向疾病预防中心等机构通报新型流感病例。然而，患者在被感染后通常不会立即就医。从医院向疾控中心发送信息，由疾控中心对这些信息进行分析和总结，也需要一些时间。因此，当公众意识到新型流感大流行时，该疾病可能已经传播了一到两周，具有滞后性。谷歌发现，在流感传播过程中，其搜索引擎中频繁搜索的词条会与平时有所不同，词条的使用频率与流感传播的时间和地点都存在相关性。谷歌找到了 45 个与流感爆发密切相关的搜索词组，并将它们整合到特定的数学模型中，以预测流感的传播，甚至预测流感的传播地点。相关研究成果已发表在 Nature18 上。 2008年，微软收购了美国科技风险投资企业Farecast。Farecast拥有能够预测机票价格趋势和涨跌幅度的机票预测系统。该系统已被纳入微软的必应搜索引擎。到2012年，该系统为每位乘客节省了近50美元的票价，预测准确率高达75%。 目前，数据已成为一种可以与物质资产和人力资本相媲美的重要生产要素。随着多媒体、社交媒体、物联网的发展，企业收集的信息将越来越多，数据量将呈指数级增长。大数据在为企业和消费者创造价值方面具有巨大且不断增长的潜力。 大数据的发展1970年代后期，出现了“数据库机”的概念，这是一种专门用于存储和分析数据的技术。 随着数据量的增加，单个大型计算机系统的存储和处理能力变得不足。 1980年代，人们提出了“share nothing”，一种并行数据库系统，以满足日益增长的数据量的需求19。 无共享系统架构基于集群的使用，每台机器都有自己的处理器、存储和磁盘。 Teradata 系统是第一个成功的商业并行数据库系统。 这种数据库最近变得非常流行。 1986 年 6 月 2 日，Teradata 向 Kmart 交付了第一个存储容量为 1TB 的并行数据库系统，以帮助北美大型零售公司扩展其数据仓库20，这是一个里程碑式的事件。 1990年代后期，并行数据库的优势在数据库领域得到广泛认可。 然而，大数据也面临着许多挑战。随着互联网服务的发展，要索引和查询的内容迅速增长。因此，搜索引擎公司不得不面对处理这样的大数据的挑战。谷歌创建了GFS21和MapReduce22编程模型，以应对互联网规模下数据管理和分析带来的挑战。此外，用户、传感器等无处不在的数据源生成的内容也对势不可挡的数据流产生了冲击，这就要求对计算架构和大规模数据处理机制进行根本性的改变。2007年1月，数据库软件的先驱Jim Gray将这种转变称为“第四范式”23。他还认为，应对这种范式的唯一方法是开发新一代的计算工具来管理、可视化和分析大量数据。2011年6月，另一个里程碑事件发生了;EMC/IDC发表了《从混沌的[1]中提取价值》的研究报告，首次介绍了大数据的概念和潜力。该研究报告引发了业界和学术界对大数据的极大兴趣。 近年来，EMC、Oracle、IBM、微软、谷歌、亚马逊、Facebook等大公司几乎都启动了大数据项目。以IBM为例，自2005年以来，IBM共投资160亿美元进行了30次与大数据相关的收购。在学术界，大数据也受到了关注。2008年，《自然》杂志出版了大数据专刊。2011年，《科学》杂志还推出了关于大数据“数据处理”关键技术的专刊。2012年，欧洲信息学与数学研究联盟(ERCIM)新闻出版了大数据专刊。2012年初，在瑞士达沃斯论坛上，一份题为《大数据，大影响》的报告宣布，大数据已经成为一种新的经济资产，就像货币或黄金一样。国际研究机构Gartner在2012年至2013年发布了《Hype Cycles》，将大数据计算、社会分析、存储数据分析等分类为48个最值得关注的新兴技术。 美国等许多国家政府也非常重视大数据。 2012 年 3 月，奥巴马政府宣布投资 2 亿美元启动“大数据研发计划”，这是继 1993 年“信息高速公路”计划之后的第二个重大科技发展计划。2012 年 7 月， 日本总务省发布的“大力发展ICT日本”项目表明，大数据发展应成为国家战略，应用技术应成为重点。 2012年7月，联合国发布大数据促发展报告，总结了各国政府如何利用大数据更好地服务和保护人民。 大数据的挑战大数据时代急剧增加的数据洪流给数据的获取、存储、管理和分析带来了巨大的挑战。传统的数据管理和分析系统是基于关系数据库管理系统（RDBMS）。但是，此类 RDBMS 仅适用于结构化数据，而非半结构化或非结构化数据。此外，RDBMS 越来越多地使用越来越昂贵的硬件。显然，传统的 RDBMS 无法处理海量和异构的大数据。研究界从不同的角度提出了一些解决方案。例如，利用云计算来满足大数据对基础设施的要求，如成本效率、弹性、平滑升级/降级等。对于大规模无序数据集的永久存储和管理解决方案，分布式文件系统 [24] 和 NoSQL [25] 数据库是不错的选择。这样的编程框架在处理集群任务方面取得了巨大的成功，特别是在网页排名方面。基于这些创新技术或平台，可以开发出各种大数据应用。此外，部署大数据分析系统并非易事。 一些文献 [26-28] 讨论了大数据应用程序开发中的障碍。 主要挑战如下： 数据表示：许多数据集在类型、结构、语义、组织、粒度和可访问性方面都有一定程度的异构性。数据表示旨在使数据对计算机分析和用户解释更有意义。不恰当的数据表达会降低原始数据的价值，甚至可能阻碍有效的数据分析。高效的数据表示应反映数据的结构、类别和类型，以及集成的技术，以便对不同的数据集进行高效的操作。 减少冗余和数据压缩：通常，数据集中存在高度冗余。 不影响数据潜在价值的前提下减少冗余和压缩数据，可以有效降低整个系统的间接成本。 例如，传感器网络生成的大多数数据都是高度冗余的，可以成数量级地过滤和压缩。 数据生命周期管理：与存储系统相对缓慢的进步相比，无处不在的传感和计算正在以前所未有的速度和规模生成数据。 我们面临着许多紧迫的挑战，其中之一就是当前的存储系统无法支持如此海量的数据。 一般来说，大数据中隐藏的价值取决于数据的新鲜度。 因此，应制定与分析值相关的数据重要性原则，以决定哪些数据应存储，哪些数据应丢弃。 分析机制：大数据分析系统要在有限的时间内处理海量异构数据。 然而，传统的RDBMS设计严谨，缺乏可扩展性，无法满足性能要求。 非关系型数据库在处理非结构化数据方面表现出了独特的优势，开始成为大数据分析的主流。 尽管如此，非关系型数据库在性能和特定应用方面仍然存在一些问题。 我们将在 RDBMS 和非关系数据库之间找到一个折中的解决方案。 例如，一些企业采用了混合数据库架构，融合了两种数据库（如 Facebook 和淘宝）的优点。 数据保密性：目前大部分大数据服务商或拥有者由于能力有限，无法有效维护和分析如此庞大的数据集。 他们必须依靠专业人员或工具来分析这些数据，这增加了潜在的安全风险。 例如，交易数据集通常包括一组完整的运营数据，以驱动关键业务流程。 此类数据包含最低粒度的详细信息和一些敏感信息，例如信用卡号。 因此，只有在采取适当的预防措施保护此类敏感数据，以确保其安全时，才能将大数据的分析交付给第三方进行处理。 能源管理：大型机计算系统的能源消耗从经济和环境的角度都备受关注。 随着数据量和分析需求的增加，大数据的处理、存储和传输必然会消耗越来越多的电能。 因此，在保证可扩展性和可访问性的同时，需要建立大数据系统级的功耗控制和管理机制。 可扩展性：大数据分析系统必须支持当前和未来的数据集。 分析算法必须能够处理日益扩展和更复杂的数据集。 合作：大数据分析是一项跨学科研究，需要不同领域的专家合作，挖掘大数据的潜力。 必须建立一个全面的大数据网络架构，帮助各个领域的科学家和工程师访问不同类型的数据，充分利用他们的专业知识，协同完成分析目标。 相关技术为了深入了解大数据，本节将介绍与大数据密切相关的几项基础技术，包括云计算、物联网、数据中心和Hadoop。 大数据与云计算的关系云计算与大数据密切相关。云计算的关键组成部分如图3所示。大数据是计算密集型操作的对象，强调云系统的存储容量。云计算的主要目标是集中管理使用庞大的计算和存储资源，为大数据应用提供细粒度的计算能力。云计算的发展为大数据的存储和处理提供了解决方案。另一方面，大数据的出现也加速了云计算的发展。基于云计算的分布式存储技术可以有效地管理大数据;云计算的并行计算能力可以提高大数据采集和分析的效率。 尽管在云计算和大数据领域有很多重叠的技术，但它们在以下两个方面有所不同。首先，概念在一定程度上是不同的。云计算改变了IT架构，而大数据影响了业务决策。而大数据的顺利运行有赖于云计算作为基础设施。 第二，大数据和云计算的目标客户不同。云计算是一种针对首席信息官(CIO)的技术和产品，是一种先进的IT解决方案。大数据是一种针对首席执行官(CEO)的产品，专注于商业运营。由于决策者可能直接感受到来自市场竞争的压力，他们必须以更有竞争力的方式击败商业对手。随着大数据和云计算的发展，这两种技术必然会越来越多地交织在一起。云计算的功能与计算机和操作系统类似，提供系统级资源;大数据在云计算支持下的上层运行，提供类似数据库的功能和高效的数据处理能力。EMC总裁基辛格表示，大数据的应用必须基于云计算。 应用需求的快速增长和由虚拟化技术发展而来的云计算推动了大数据的演变。因此，云计算不仅为大数据提供计算和处理，它本身也是一种服务模式。在一定程度上，云计算的进步也促进了大数据的发展，两者相辅相成。 大数据与物联网的关系在物联网范式中，大量的网络传感器被嵌入到现实世界中的各种设备和机器中。这种传感器部署在不同的领域，可以收集各种数据，如环境数据、地理数据、天文数据和物流数据。移动设备、交通设施、公共设施、家电等都可以是物联网中的数据采集设备，如图4所示。 物联网产生的大数据由于采集的数据类型不同，与普通大数据相比具有不同的特征，其中最经典的特征包括异质性、多样性、非结构化、噪声和高冗余。虽然目前物联网数据还不是大数据的主导部分，但据惠普预测，到2030年，传感器数量将达到一万亿，物联网数据将成为大数据中最重要的部分。英特尔公司的一份报告指出，物联网大数据有三个符合大数据范式的特征:(1)丰富的终端产生大量数据;(ii)物联网产生的数据通常是半结构化或非结构化的;(iii)物联网数据只有经过分析才有用。 目前，物联网的数据处理能力已经落后于采集的数据，加快大数据技术的引入，促进物联网的发展刻不容缓。许多物联网运营商都意识到大数据的重要性，因为物联网的成功取决于大数据与云计算的有效整合。物联网的广泛应用也将使许多城市进入大数据时代。 在物联网应用中采用大数据的需求迫切，而大数据的发展已经落后。人们普遍认为，物联网和大数据是相互依存、共同发展的:一方面，物联网的广泛部署推动了数据在数量和类别上的高速增长，为大数据的应用和发展提供了机遇;另一方面，大数据技术在物联网中的应用也加速了物联网的研究进展和商业模式。 数据中心在大数据范式中，数据中心不仅是集中存储数据的平台，还承担着获取数据、管理数据、组织数据、利用数据价值和功能等更多的职责。数据中心主要关注的是“数据”而不是“中心”。它拥有大量的数据，并根据其核心目标和发展路径对数据进行组织和管理，这比拥有一个好的站点和资源更有价值。大数据的出现给数据中心带来了良好的发展机遇，同时也带来了巨大的挑战。大数据是一个新兴的范式，它将推动数据中心的基础设施和相关软件的爆炸式增长。物理数据中心网络是支持大数据的核心，也是目前[29]最迫切需要的关键基础设施。 大数据需要数据中心提供强大的后台支持。大数据范式对存储容量、处理容量以及网络传输容量都有更严格的要求。企业必须考虑到数据中心的发展，以提高在有限的性价比下快速有效的处理大数据的能力。数据中心需要为基础设施提供大量节点，构建高速的内部网络，有效散热，有效备份数据。只有建立一个高效节能、稳定、安全、可扩展、冗余的数据中心，才能保证大数据应用的正常运行。 大数据应用的增长加速了数据中心的革命和创新。许多大数据应用已经形成了自己独特的体系结构，直接推动了与数据中心相关的存储、网络和计算技术的发展。随着结构化和非结构化数据量的不断增长，分析数据来源的多样化，数据中心的数据处理和计算能力需要大幅提升。此外，随着数据中心规模的日益扩大，如何降低数据中心发展的运营成本也是一个重要的问题。 大数据赋予数据中心更多的功能。在大数据范式下，数据中心不仅要关注硬件设施，还要加强软能力，即大数据的获取、处理、组织、分析和应用的能力。数据中心可以帮助业务人员分析现有数据，发现业务运行中的问题，并从大数据中制定解决方案。 大数据与hadoop的关系目前Hadoop被广泛应用于行业中的大数据应用，如垃圾邮件过滤、网络搜索、点击流分析、社交推荐等。此外，现在有相当多的学术研究基于Hadoop。下面给出一些具有代表性的案例。正如2012年6月宣布的那样，雅虎在四个数据中心的42,000台服务器上运行Hadoop，以支持其产品和服务，如搜索和垃圾邮件过滤等。目前最大的Hadoop集群有4000个节点，但随着Hadoop 2.0的发布，节点数量将增加到10000个。同月，Facebook宣布他们的Hadoop集群可以处理100个PB数据，比2012年11月每天增加0.5个PB。[30]中列出了一些使用Hadoop进行分布式计算的知名机构。此外，许多公司提供Hadoop商业执行和/或支持，包括Cloudera、IBM、MapR、EMC和Oracle 在现代工业机械和系统中，传感器被广泛应用于收集信息，用于环境监测、故障预测等。Bahga和[31]中的其他人提出了一个用于数据组织和云计算基础设施的框架，称为CloudView。CloudView使用混合架构、本地节点和基于Hadoop的远程集群来分析机器生成的数据。局部节点用于实时故障预测;基于Hadoop的集群用于复杂的离线分析，例如案例驱动的数据分析. 基因组数据的指数增长和测序成本的急剧下降将生物科学和生物医学转变为数据驱动的科学。在[32]中，Gunarathne等人利用云计算基础设施、Amazon AWS、Microsoft Azune，以及基于MapReduce、Hadoop和Microsoft DryadLINQ的数据处理框架，运行了两个并行的生物医药应用:(i)基因组片段的组装;(ii)化学结构分析的降维。在随后的应用程序中，166-D数据集包括2600万个数据点。作者在效率、成本和可用性方面比较了所有框架的性能。通过研究，作者得出结论，松耦合将越来越多地应用于电子云的研究，并行编程技术(MapReduce)框架可以为用户提供更方便的服务界面，减少不必要的成本。 大数据的生成和获取大数据的存储数据的爆炸式增长对存储和管理提出了更加严格的要求。在本节中，我们将重点讨论大数据的存储。大数据存储是指对大规模数据集进行存储和管理，同时实现数据访问的可靠性和可用性。我们将回顾包括海量存储系统、分布式存储系统和大数据存储机制在内的重要问题。一方面，存储基础设施需要为信息存储服务提供可靠的存储空间;另一方面，它必须为海量数据的查询和分析提供强大的访问接口。 传统上，数据存储设备作为服务器的辅助设备，用于存储、管理、查找和分析结构化RDBMS中的数据。 随着数据的急剧增长，数据存储设备变得越来越重要，许多互联网公司追求大容量的存储以具有竞争力。 因此，迫切需要对数据存储进行研究。 海量数据存储系统为了满足海量数据的需求，各种存储系统应运而生。现有的海量存储技术可分为DAS (Direct Attached storage)和网络存储，网络存储又可分为NAS (network Attached storage)和SAN (storage Area network)。。 在DAS中，各种硬盘与服务器直接相连，数据管理以服务器为中心，存储设备为外围设备，每个设备占用一定的I/O资源，由单个应用软件进行管理。因此，DAS只适用于对接规模较小的服务器。但由于DAS的可扩展性较低，在增加存储容量时，其效率并不理想，即极大地限制了其可升级性和可扩展性。因此，DAS主要用于个人电脑和小型服务器 网络存储就是利用网络为用户提供数据访问和共享的联合接口。网络存储设备包括专用的数据交换设备、磁盘阵列、tap库等存储介质以及专用的存储软件。具有较强的可扩展性。 NAS实际上是网络的辅助存储设备。它通过集线器或交换机通过TCP/IP协议直接连接到网络。在NAS中，数据以文件的形式传输。与DAS相比，NAS服务器通过网络间接访问存储设备，大大减少了I/O负担。 NAS是面向网络的，而SAN是专门为可伸缩和带宽密集型网络的数据存储而设计的，例如，具有光纤连接的高速网络。在SAN中，数据存储管理是在存储局域网内相对独立的，它利用内部任意节点之间基于多路径的数据交换，实现最大程度的数据共享和数据管理。 从数据存储系统的组织结构上看，DAS、NAS和SAN均可分为三部分:(1)磁盘阵列:磁盘阵列是存储系统的基础，是数据存储的根本保障;(ii)提供一个或多个磁盘阵列和服务器之间连接的连接和网络子系统;(iii)存储管理软件，处理多台服务器的数据共享、容灾等存储管理任务。。 分布式存储系统与CAP大数据带来的第一个挑战是如何开发一个大规模的分布式存储系统来高效地处理和分析数据。使用分布式系统存储海量数据，需要考虑以下因素: 一致性（Consistency）:分布式存储系统需要多台服务器协同存储数据。服务器越多，服务器故障的概率就越大。通常数据被分成多个部分存储在不同的服务器上，以确保在服务器故障时的可用性。但是，服务器故障和并行存储可能会导致相同数据的不同副本之间不一致。一致性是指确保相同数据的多个副本是相同的。 可用性（Availability）:分布式存储系统运行在多台服务器上。随着使用更多的服务器，服务器故障是不可避免的。如果整个系统不受严重影响，就可以满足客户的读写要求。这个属性称为可用性。 分区容错（Partition Tolerance）：分布式存储系统中的多个服务器通过网络连接。 网络可能存在链路/节点故障或临时拥塞。 分布式系统应该对网络故障引起的问题有一定的容忍度。 当网络被分区时，我们希望分布式存储仍然可以很好地工作。 Eric Brewer在2000年提出了CAP[80,81]理论，指出分布式系统不能同时满足一致性、可用性和分区容错的要求;三个要求中最多可以同时满足两个。麻省理工学院的Seth Gilbert和Nancy Lynch在2002年证明了CAP理论的正确性。由于一致性、可用性和分区容错不能同时实现，我们可以根据不同的设计目标，通过忽略分区容错来拥有CA系统，通过忽略可用性来拥有CP系统，以及忽略一致性的AP系统。下面将对这三个系统进行讨论。 CA系统没有分区容错，也就是说，它们不能处理网络故障。因此，CA系统通常被视为只有一台服务器的存储系统，例如传统的小型关系数据库。这样的系统以数据的单副本为特征，这样很容易保证一致性。良好的关系数据库设计保证了可用性。然而，由于CA系统不能处理网络故障，因此它们不能扩展到使用许多服务器。因此，大多数大型存储系统都是CP系统和AP系统。 与CA系统相比，CP系统保证了分区的容错。因此，CP系统可以扩展为分布式系统。CP系统通常维护相同数据的多个副本，以确保一定程度的容错。CP系统还确保数据一致性，即保证相同数据的多个副本完全相同。然而，CP不能确保良好的可用性，因为保证一致性的成本很高。因此，CP系统适用于负载适中但对数据准确性要求严格的场景(如交易数据)。BigTable和Hbase是两种流行的CP系统。 AP 系统也确保分区容错。 AP 系统与 CP 系统的不同之处在于，AP 系统确保可用性。 同时，AP系统只保证最终一致性，而不是前两个系统的强一致性。 因此，AP系统只适用于请求频繁但对准确性要求不高的场景。 例如，在在线社交网络服务（SNS）系统中，对数据的并发访问很多，但一定量的数据错误是可以容忍的。 此外，由于AP系统确保最终的一致性，在一定的延迟后仍然可以获得准确的数据。 因此，AP系统也可以在没有严格实时要求的情况下使用。 Dynamo 和 Cassandra 是两个流行的 AP 系统。 大数据的存储机制传统数据分析大数据分析方法大数据分析的架构大数据挖掘和分析工具大数据的应用结论、有待解决的问题和展望参考文献见原论文。 持续更新中...","link":"/pages/big-data-survey/"},{"title":"不知道做啥？看下那些真实业务场景下的技术问题","text":"(云计算) 如何解决Serverless函数冷启动的问题？ (智能运维) 如何对业务指标和基础监控指标做异常检测？","link":"/pages/problems/"},{"title":"(智能运维) 如何对监控指标做异常检测？","text":"背景参考链接 腾讯 织云Metis时间序列异常检测全方位解析 美团 外卖订单量预测异常报警模型实践 滴滴 滴滴出行海量数据场景下的智能监控与故障定位实践 有空就更新...","link":"/pages/ts-anomaly-detection/"},{"title":"一文了解CDN加速原理","text":"CDN（Content Delivery Network，内容分发网络）是构建在现有互联网基础之上的一层智能虚拟网络，通过在网络各处部署节点服务器，实现将源站内容分发至所有CDN节点，使用户可以就近获得所需的内容。CDN服务缩短了用户查看内容的访问延迟，提高了用户访问网站的响应速度与网站的可用性，解决了网络带宽小、用户访问量大、网点分布不均等问题。 CDN加速原理当用户访问使用CDN服务的网站时，本地DNS服务器通过CNAME方式将最终域名请求重定向到CDN服务。CDN通过一组预先定义好的策略(如内容类型、地理区域、网络负载状况等)，将当时能够最快响应用户的CDN节点IP地址提供给用户，使用户可以以最快的速度获得网站内容。使用CDN后的HTTP请求处理流程如下： CDN节点有缓存场景 HTTP请求流程说明： 1、用户在浏览器输入要访问的网站域名，向本地DNS发起域名解析请求。 2、域名解析的请求被发往网站授权DNS服务器。 3、网站DNS服务器解析发现域名已经CNAME到了www.example.com.c.cdnhwc1.com。 4、请求被指向CDN服务。 5、CDN对域名进行智能解析，将响应速度最快的CDN节点IP地址返回给本地DNS。 6、用户获取响应速度最快的CDN节点IP地址。 7、浏览器在得到速度最快节点的IP地址以后，向CDN节点发出访问请求。 8、CDN节点将用户所需资源返回给用户。 CDN节点无缓存场景 HTTP请求流程说明： 1、用户在浏览器输入要访问的网站域名，向本地DNS发起域名解析请求。 2、域名解析的请求被发往网站授权DNS服务器。 3、网站DNS服务器解析发现域名已经CNAME到了www.example.com.c.cdnhwc1.com。 4、请求被指向CDN服务。 5、CDN对域名进行智能解析，将响应速度最快的CDN节点IP地址返回给本地DNS。 6、用户获取响应速度最快的CDN节点IP地址。 7、浏览器在得到速度最快节点的IP地址以后，向CDN节点发出访问请求。 8、CDN节点回源站拉取用户所需资源。 9、将回源拉取的资源缓存至节点。 10、将用户所需资源返回给用户。 域名加速配置根据上面的原理，要做域名加速，就得使用阿里云/腾讯云等云厂商的cdn服务，配置的基本流程就是： 输入你要加速的域名www.abc.com, 它返回一个域名给你，比如www.abc.com.cdn.dnsv1.com。 配置源站地址：可以是ip地址形式或域名形式。CDN节点不包含请求内容时将访问该地址(域名)获取请求内容 缓存规则配置：比如配置缓存过期策略，不缓存动态文件(比如.php)等。默认的缓存过期策略通常与http头的Cache-Control， max-age等字段相关，可参考云厂商的官方文档。 去域名控制台配置域名解析，将www.abc.com CNAME到 abc.com.cdn.dnsv1.com 参考链接 CDN的加速原理是什么？ 腾讯云域名加速配置 阿里云域名加速配置 腾讯云CDN节点缓存过期配置","link":"/pages/wiki-cdn/"}],"tags":[{"name":"Serverless","slug":"Serverless","link":"/tags/Serverless/"},{"name":"大数据","slug":"大数据","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"智能运维","slug":"智能运维","link":"/tags/%E6%99%BA%E8%83%BD%E8%BF%90%E7%BB%B4/"}],"categories":[{"name":"问题","slug":"问题","link":"/categories/%E9%97%AE%E9%A2%98/"},{"name":"综述","slug":"综述","link":"/categories/%E7%BB%BC%E8%BF%B0/"},{"name":"一文了解","slug":"一文了解","link":"/categories/%E4%B8%80%E6%96%87%E4%BA%86%E8%A7%A3/"}]}